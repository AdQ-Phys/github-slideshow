{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.6-tf'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первое знакомство с нейронной сетью\n",
    "\n",
    "Рассмотрим конкретный пример нейронной сети, которая обучается классифика-\n",
    "ции рукописных цифр и создана с помощью библиотеки Keras для Python. Если\n",
    "у вас нет опыта использования Keras или других подобных библиотек, возможно,\n",
    "вы не все поймете в этом первом примере. Может быть, вы еще не установили Keras;\n",
    "в этом нет ничего страшного. В следующей главе мы рассмотрим каждый элемент\n",
    "в примере и подробно объясним их. Поэтому не волнуйтесь, если какие-то шаги\n",
    "покажутся непонятным и или похожими на магию. В конце концов, мы должны\n",
    "с чего-то начать.\n",
    "\n",
    "Перед нами стоит задача: реализовать классификацию черно-белых изображений\n",
    "рукописных цифр (28 × 28 пикселов) по 10 категориям (от 0 до 9). Мы будем\n",
    "использовать набор данных MNIST, популярный в сообществе исследователей\n",
    "глубокого обучения, который существует практически столько же, сколько сама\n",
    "область машинного обучения, и широко используется для обучения. Этот набор\n",
    "содержит 60 000 обучающих изображений и 10 000 контрольных изображений,\n",
    "собранных Национальным институтом стандартов и технологий США (National\n",
    "Institute of Standards and Technology — часть NIST в аббревиатуре MNIST) в 1980‐х.\n",
    "«Решение» задачи MNIST можно рассматривать как своеобразный аналог «Hello\n",
    "World» в глубоком обучении — часто это первое действие, которое выполняется,\n",
    "чтобы убедиться, что алгоритмы действуют в точности как ожидалось. По мере\n",
    "углубления в практику машинного обучения вы увидите, что MNIST часто упоминается в научных статьях, блогах и т. д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных MNIST уже входит в состав Keras в форме набора из четырех мас-\n",
    "сивов Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь train_images и  train_labels  — это тренировочный набор, то есть данные,\n",
    "необходимые для обучения. После обучения модель будет проверяться тестовым\n",
    "(или контрольным) набором, test_images и  test_labels.\n",
    "Изображения хранятся в массивах Numpy, а метки — в массиве цифр от 0 до 9. Изо-\n",
    "бражения и метки находятся в прямом соответствии, один к одному.\n",
    "\n",
    "Рассмотрим обучающие данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И контрольные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала передадим нейронной сети обучающие данные, train_images и  train_labels.\n",
    "В результате этого сеть обучится сопоставлять изображения с метками.\n",
    "Затем мы предложим сети классифицировать изображения в  test_images и\n",
    "проверим точность классификации по меткам из test_labels.\n",
    "Теперь сконструируем сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основным строительным блоком нейронных сетей является слой (или уровень),\n",
    "модуль обработки данных, который можно рассматривать как фильтр для данных.\n",
    "Он принимает некоторые данные и выводит их в более полезной форме. В частности,\n",
    "слои извлекают представления из подаваемых в них данных, которые, как мы\n",
    "надеемся, будут иметь больше смысла для решаемой задачи. Фактически методика\n",
    "глубокого обучения заключается в объединении простых слоев, реализующих не-\n",
    "которую форму поэтапной очистки данных. Модель глубокого обучения можно\n",
    "сравнить с ситом, состоящим из последовательности фильтров все более тонкой\n",
    "очистки данных — слоев.\n",
    "\n",
    "В данном случае наша сеть состоит из последовательности двух слоев Dense , которые являются тесно связанными (их еще называют полносвязными) нейронными слоями. Второй (и последний) слой — это 10-переменный слой потерь (softmax\n",
    "layer), возвращающий массив с 10 оценками вероятностей (в сумме дающих 1).\n",
    "Каждая оценка определяет вероятность принадлежности текущего изображения\n",
    "к одному из 10 классов цифр.\n",
    "\n",
    "Чтобы подготовить сеть к обучению, нужно настроить еще три параметра для этапа\n",
    "компиляции:\n",
    "\n",
    "* функцию потерь, которая определяет, как сеть должна оценивать качество\n",
    "своей работы на обучающих данных и, соответственно, как корректировать ее\n",
    "в правильном направлении;\n",
    "* оптимизатор — механизм, с помощью которого сеть будет обновлять себя,\n",
    "опираясь на наблюдаемые данные и функцию потерь;\n",
    "* метрики для мониторинга на этапах обучения и тестирования — здесь нас\n",
    "будет интересовать только точность (доля правильно классифицированных\n",
    "изображений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Перед обучением мы выполним предварительную обработку данных, преобразовав\n",
    "их в форму, которую ожидает получить нейронная сеть, и масштабируем их так,\n",
    "чтобы все значения оказались в интервале [0, 1] . Исходные данные — обучаю-\n",
    "щие изображения — хранятся в трехмерном массиве (60000, 28, 28) типа uint8 ,\n",
    "значениями в котором являются числа в интервале [0, 255] . Мы преобразуем его\n",
    "в массив (60000, 28 * 28) типа float32 со значениями в интервале [0, 1] ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам также нужно закодировать метки категорий. Этот шаг подробнее объясняется позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно начинать обучение сети, для чего в случае использования библиотеки\n",
    "Keras достаточно вызвать метод fit сети — он пытается адаптировать (fit) модель\n",
    "под обучающие данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.2599 - acc: 0.9239\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.1038 - acc: 0.9695\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0680 - acc: 0.9795\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0499 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0372 - acc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa5f2ad6650>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе обучения отображаются две величины: потери сети на обучающих\n",
    "данных и точность сети на обучающих данных.\n",
    "В данном случае мы достигли точности 0,9972 (99,7%) на обучающих данных. Теперь\n",
    "проверим, как модель распознает контрольный набор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 18us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_acc:', 0.9813)\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность на контрольном наборе составила 98,1 % — немного меньше, чем на трени-\n",
    "ровочном наборе. Эта разница между точностью на тренировочном и контрольном\n",
    "наборах демонстрирует пример переобучения (overfitting), когда модели машинного\n",
    "обучения показывают худшую точность на новом наборе данных по сравнению\n",
    "с тренировочным. Основная речь о переобучении пойдет позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.3505327e-11, 4.1083820e-07, 9.9999940e-01, 8.4809969e-08,\n",
       "       7.5834258e-17, 3.2604346e-09, 1.3253010e-09, 3.4211181e-17,\n",
       "       7.3030762e-08, 6.4009145e-15], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr=network.predict(test_images)[1]\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa570813d10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test_images[1].reshape([28,28]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
